{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib -q\n"
      ],
      "metadata": {
        "id": "Qd0U5FDa2xHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.oauth2.service_account import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Path to your service account JSON key\n",
        "SERVICE_ACCOUNT_FILE = '/content/inspired-truth-422708-n2-60693c79cb65.json'\n",
        "\n",
        "# Scopes required for Google Calendar API\n",
        "SCOPES = ['https://www.googleapis.com/auth/calendar']\n",
        "\n",
        "# The email of the specific calendar to access\n",
        "CALENDAR_ID = 'ebc8bb590a66d7a545bccb9ae0662489f01f15abfb02541f5104dc617ade90a0@group.calendar.google.com'  # Replace with your calendar's email\n",
        "\n",
        "\n",
        "# Authenticate using the service account\n",
        "credentials = Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE, scopes=SCOPES\n",
        ")\n",
        "\n",
        "# Build the Google Calendar API service\n",
        "service = build('calendar', 'v3', credentials=credentials)\n",
        "\n",
        "# List upcoming events\n",
        "print(\"Fetching events from the calendar...\")\n",
        "events_result = service.events().list(\n",
        "    calendarId=CALENDAR_ID,\n",
        "    maxResults=10,\n",
        "    singleEvents=True,\n",
        "    orderBy='startTime'\n",
        ").execute()\n",
        "\n",
        "events = events_result.get('items', [])\n",
        "\n",
        "if not events:\n",
        "    print(\"No upcoming events found.\")\n",
        "for event in events:\n",
        "    start = event['start'].get('dateTime', event['start'].get('date'))\n",
        "    print(f\"Event: {event['summary']} at {start}\")\n",
        "\n",
        "# # Example: Create a new event\n",
        "# event = {\n",
        "#     'summary': 'Service Account Event',\n",
        "#     'location': 'Virtual Meeting',\n",
        "#     'description': 'Created using a service account.',\n",
        "#     'start': {\n",
        "#         'dateTime': '2025-01-15T10:00:00-07:00',\n",
        "#         'timeZone': 'America/Los_Angeles',\n",
        "#     },\n",
        "#     'end': {\n",
        "#         'dateTime': '2025-01-15T11:00:00-07:00',\n",
        "#         'timeZone': 'America/Los_Angeles',\n",
        "#     },\n",
        "# }\n",
        "\n",
        "# Uncomment to create an event\n",
        "# event = service.events().insert(calendarId=CALENDAR_ID, body=event).execute()\n",
        "# print(f\"Event created: {event.get('htmlLink')}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cSBxyZH2y8B",
        "outputId": "f24e57ff-ddd9-4083-ab28-04889ddcca96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching events from the calendar...\n",
            "Event: Service Account Event at 2025-01-15T10:00:00+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXGGtgZGnEOu"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U tavily-python langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SigZwZ0WlzOU"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cth_5hTcolsC",
        "outputId": "48a7e963-3511-4907-faf7-48e175d8366f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/109.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain_groq -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyYbJ0vFDPEr"
      },
      "outputs": [],
      "source": [
        "!pip install gTTS -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oIH-76I31Ev"
      },
      "outputs": [],
      "source": [
        "from gtts import gTTS\n",
        "import os\n",
        "from groq import Groq\n",
        "from tempfile import NamedTemporaryFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZflMZS-ql4wx"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBZyR3U0ppTu",
        "outputId": "21c7aa8d-9f8a-45cf-d2e5-2f6b04d21612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY: ··········\n"
          ]
        }
      ],
      "source": [
        "_set_env(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO5lW7M5oL1i"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api_key')\n",
        "langsmith_api_key = userdata.get('langsmith_api_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwnGujnIZK1K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith_api_key\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = 'ENCODE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtDtnT-1ptFy"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(max_results=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub-YHI_Wa0L0"
      },
      "outputs": [],
      "source": [
        "combined_result = '\\n'.join([item['content'] for item in result])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "_cml3FXmbHSc",
        "outputId": "a99436d1-14d4-44c9-fbaf-70604e5ae034"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nodes¶ In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id). Similar to NetworkX, you add these nodes to a graph using the add_node method:\\nLangGraph Nodes. Nodes are defined as Python functions that can perform a set of actions. For example, a node can integrate with a large language model, process information, call an external API, or any other task. A LangGraph node takes the state of the graph as a parameter and returns an updated state after it is executed.\\nNodes (Tasks): Nodes are like the workstations on the assembly line. Each node performs a specific task on the product. In LangGraph, nodes are Python functions that take the current state, do some work, and return an updated state. Next, we define the nodes, each representing a task in our sandwich-making process.\\nNodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making\\nIn LangGraph, each node represents an LLM agent, and the edges are the communication channels between these agents. This structure allows for clear and manageable workflows, where each agent performs specific tasks and passes information to other agents as needed. State management. One of LangGraph\\'s standout features is its automatic state'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDPACURYGxua",
        "outputId": "1ac27c1e-1edf-4f82-e464-8a639d0d2fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "mgm1802cGs-M",
        "outputId": "c4b3dde2-a183-49ae-cf30-a448295bb124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.51G/1.51G [00:27<00:00, 59.3MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9a4dc52a1302>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maudio_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"turbo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "audio_model = whisper.load_model(\"turbo\").to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdcWzH8k4ASV"
      },
      "outputs": [],
      "source": [
        "# from langchain_groq import ChatGroq\n",
        "# audio_model = ChatGroq(groq_api_key=groq_api_key, model_name=\"whisper-large-v3-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZvfxjRR4MVn"
      },
      "outputs": [],
      "source": [
        "def speech_to_text(audio_path):\n",
        "    transcription = audio_model.transcribe(audio_path)[\"text\"]\n",
        "    return transcription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tcKOqCl67hA"
      },
      "outputs": [],
      "source": [
        "x = speech_to_text('/content/my name is will.m4a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7du9A87G7FVn",
        "outputId": "9cbdcf69-4353-48f0-bab2-bd67e0b0395b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' My name is Phil.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRPZHeUmwFec"
      },
      "outputs": [],
      "source": [
        "!pip install cassio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cih310E1Y4d"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5gdhHtYjGOz"
      },
      "outputs": [],
      "source": [
        "import cassio\n",
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:KbNWBbtOOzasZtCrdFchdQef:795f451cdb79dcc9a02f5b364e76e587c367a75e07c449b2c7f32dab6d6cc516\"\n",
        "ASTRA_DB_ID = \"de2739c2-f9d0-49d1-acc8-2fb1e94759ec\"\n",
        "cassio.init(token = ASTRA_DB_APPLICATION_TOKEN ,database_id = ASTRA_DB_ID )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2sPYipDjuM_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tiktoken langchainhub langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1SnwivQkEC2"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "urls = [\n",
        "    \"https://en.wikipedia.org/wiki/Max_Life_Insurance\",\n",
        "    \"https://www.maxlifeinsurance.com/term-insurance-plans/premium-calculator?utmCode=1311271&utm_theme=1Crore&utm_source=google&utm_medium=cpc&utm_campaign=1_Brand_Exact_CitiesNew_TCPA_Experiment_25072024_ECPC&utm_content=NeutralKeywords_02122024&utm_term=max%20life%20insurance%20co&gclid=Cj0KCQiAkJO8BhCGARIsAMkswyjBqeASWdTfnkqhC3YD0bzMJeAku11UF2beXZPAceVSeBsye9Em6k0aAjquEALw_wcB\",\n",
        "    \"https://www.maxlifeinsurance.com/life-insurance-plans\",\n",
        "    \"https://www.maxlifeinsurance.com/blog/all-products\" ,\n",
        "    \"https://www.maxlifeinsurance.com/term-insurance-plans/smart-secure-plus-plan\",\n",
        "    \"https://www.maxlifeinsurance.com/term-insurance-plans/smart-total-elite-protection-plan\",\n",
        "    \"https://www.maxlifeinsurance.com/term-insurance-plans/saral-jeevan-bima\",\n",
        "    \"https://www.maxlifeinsurance.com/about-us\",\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VQ4Ub4ZsZaY"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IoyKJSYlAaj"
      },
      "outputs": [],
      "source": [
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "doc_list = [item[0] for item in docs]\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=100)\n",
        "doc_chunks = text_splitter.split_documents(doc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqH3E6IBm66I"
      },
      "outputs": [],
      "source": [
        "len(doc_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATxDQ7-onZ6h"
      },
      "outputs": [],
      "source": [
        "doc_chunks[36]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3IN-mBP2Dxk"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade huggingface_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLaLRhYM1rWx"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_huggingface -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKo6rMYdoKbG"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embedd = HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihdqR4P_pcz2"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "astra_vdb = Cassandra(embedding = embedd ,\n",
        "                      table_name= \"encode_demo\" ,\n",
        "                      session = None ,\n",
        "                      keyspace = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mYOob7eqXGq"
      },
      "outputs": [],
      "source": [
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "astra_vdb.add_documents(doc_chunks)\n",
        "astra_vdb_idx = VectorStoreIndexWrapper(vectorstore = astra_vdb)  ##This wrapper is for interaction with the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsxH-icBq5OV"
      },
      "outputs": [],
      "source": [
        "retriever = astra_vdb.as_retriever()\n",
        "r = retriever.invoke(\"What is Smart Secure Plus Plan\" , search_kwargs = {'k':2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXGLbdKFdq6O"
      },
      "outputs": [],
      "source": [
        "combined_r = \" \".join([item.page_content for item in r])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "pasMqoxsdvJO",
        "outputId": "fd50f62e-6155-428a-9fa2-f4df2c05c672"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Axis Max Life Smart Secure Plus Plan offers two death benefits. The Smart Secure Plus Plan is designed to fulfil your financial security requirements and provide a dependable support system for emergencies. You also get inbuilt benefits such as cover for terminal illness and a special exit value*.\\nThis term plan also offers an array of optional benefits such as joint life cover, premium breaks, additional payout on accidental death and more. With this plan, your insurance needs are completely covered. It can work as a one-stop solution for your financial security requirements. As the policy buyer, it is best to understand how the policy works to be more aware of your financial decisions.\\n(*This is only applicable for NROP (Pure Protection), Policy Term 40 and above)Axis Max Life Smart Secure Plus PlanA plan that provides comprehensive financial protection.A plan that provides comprehensive financial protection.Based on 22643 usersPLAN BENEFITS₹ 1 CrLife Cover64Critical Illness Cover₹ 46K*Tax SavingsReturn of Premium : Get back all premiums paid on survival till maturityLimited pay option : Pay premium till 60 years for a life cover till 85 years@₹987/Month~Buy NowDisclaimers:\\n~This is applicable for a 24-Year Old Healthy Male, Non-Smoker, 25 Years Policy Term, 25 Year Premium Payment Term (exclusive of GST) for Axis Max Life Smart Secure Plus Plan.\\n*Tax benefits as per prevailing tax laws, subject to change. Save Rs. 46,800 on taxes if the insurance premium amount is Rs.1.5 lakh per annum and you are a regular Individual, falling under 30% income tax slab having taxable income less than Rs. 50 lakh and Opt for Old tax regime. Axis Max Life Smart Secure Plus Plan offers two death benefits. The Smart Secure Plus Plan is designed to fulfil your financial security requirements and provide a dependable support system for emergencies. You also get inbuilt benefits such as cover for terminal illness and a special exit value*.\\nThis term plan also offers an array of optional benefits such as joint life cover, premium breaks, additional payout on accidental death and more. With this plan, your insurance needs are completely covered. It can work as a one-stop solution for your financial security requirements. As the policy buyer, it is best to understand how the policy works to be more aware of your financial decisions.\\n(*This is only applicable for NROP (Pure Protection), Policy Term 40 and above)Axis Max Life Smart Secure Plus PlanA plan that provides comprehensive financial protection.A plan that provides comprehensive financial protection.Based on 22643 usersPLAN BENEFITS₹ 1 CrLife Cover64Critical Illness Cover₹ 46K*Tax SavingsReturn of Premium : Get back all premiums paid on survival till maturityLimited pay option : Pay premium till 60 years for a life cover till 85 years@₹987/Month~Buy NowDisclaimers:\\n~This is applicable for a 24-Year Old Healthy Male, Non-Smoker, 25 Years Policy Term, 25 Year Premium Payment Term (exclusive of GST) for Axis Max Life Smart Secure Plus Plan.\\n*Tax benefits as per prevailing tax laws, subject to change. Save Rs. 46,800 on taxes if the insurance premium amount is Rs.1.5 lakh per annum and you are a regular Individual, falling under 30% income tax slab having taxable income less than Rs. 50 lakh and Opt for Old tax regime. Axis Max Life Smart Secure Plus Plan offers two death benefits. The Smart Secure Plus Plan is designed to fulfil your financial security requirements and provide a dependable support system for emergencies. You also get inbuilt benefits such as cover for terminal illness and a special exit value*.\\nThis term plan also offers an array of optional benefits such as joint life cover, premium breaks, additional payout on accidental death and more. With this plan, your insurance needs are completely covered. It can work as a one-stop solution for your financial security requirements. As the policy buyer, it is best to understand how the policy works to be more aware of your financial decisions.\\n(*This is only applicable for NROP (Pure Protection), Policy Term 40 and above)Axis Max Life Smart Secure Plus PlanA plan that provides comprehensive financial protection.A plan that provides comprehensive financial protection.Based on 22643 usersPLAN BENEFITS₹ 1 CrLife Cover64Critical Illness Cover₹ 46K*Tax SavingsReturn of Premium : Get back all premiums paid on survival till maturityLimited pay option : Pay premium till 60 years for a life cover till 85 years@₹987/Month~Buy NowDisclaimers:\\n~This is applicable for a 24-Year Old Healthy Male, Non-Smoker, 25 Years Policy Term, 25 Year Premium Payment Term (exclusive of GST) for Axis Max Life Smart Secure Plus Plan.\\n*Tax benefits as per prevailing tax laws, subject to change. Save Rs. 46,800 on taxes if the insurance premium amount is Rs.1.5 lakh per annum and you are a regular Individual, falling under 30% income tax slab having taxable income less than Rs. 50 lakh and Opt for Old tax regime. the insured’s demise or upon diagnosis of a terminal illness. The option can only be exercised after a one-year waiting period from the time of policy issuance.Choosing the Right Sum Assured Option for Axis Max Life Smart Secure Plus Plan When it comes to the comprehensive financial protection of your loved ones it is essential that you select the adequate sum assured.Know more\\xa0 on how to decide the sum assured for your term insurance. You can click on the below tabs and choose the adequate sum assured:'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOKuDJuZr_rI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67be075-1d22-4f66-9bd3-ff3e82746cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from typing import Literal\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel , Field\n",
        "\n",
        "class RouteQuery(BaseModel):\n",
        "  datasource : Literal['vector-database' , 'google-search' , 'llm'] = Field(\n",
        "      description = \"Given a user query choose whether google-search , vectorstore or the llm would be most relevant for answering the query . if it's a very general question which requires searching on internet then prefer google search and if it's a very specific question regarding the insurance policies or company then prefer the vector database and if it's an instruction that can be performed by the llm then choose llm .\")\n",
        "\n",
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-8b-instant\")\n",
        "\n",
        "llm_route = llm.with_structured_output(RouteQuery)\n",
        "\n",
        "system = \"\"\"You are an expert at routing a user question to the appropriate data source.\n",
        "          Based on the query route it to the most relevant data source - vectorstore containing information about the company Max life insurance  , insurance policies and plans or google search or llm for following instruction\"\"\"\n",
        "prompt = ChatPromptTemplate([\n",
        "    ('system',system),\n",
        "    ('user','{query}')\n",
        "])\n",
        "\n",
        "Router = prompt | llm_route"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YMqlSISwtut"
      },
      "outputs": [],
      "source": [
        "s = Router.invoke({'query' : \"what is the premium of smart secure plus plan?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GDDcNrUlhlpp",
        "outputId": "0b7374f4-858d-4c16-8d4a-c5a79aca0a97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vector-database'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "s.datasource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQmD13QowySw",
        "outputId": "3b754b35-d2b1-444c-e00c-b3099fcdfc09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RouteQuery(datasource='vector-database')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "Router.invoke({'query' : \"list some retirements plans?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPGSyDH6z48O",
        "outputId": "9f8b8a18-b001-404d-80ea-64010d51f8b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RouteQuery(datasource='google-search')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "Router.invoke({'query' : \"Who is Virat Kohli?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM9ZFxjqz9NK",
        "outputId": "bb41227e-16aa-48c9-a2b2-767e7ab6481a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RouteQuery(datasource='llm')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "Router.invoke({'query' : \"schedule a meeting with the agent\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHeDeOAN1TaY"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "  documents: List[str]\n",
        "  question : str\n",
        "  generation : str\n",
        "  action : str\n",
        "  event_details : str\n",
        "  time_range : dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xET_oX9l2JvQ"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "def vectorstore(state):\n",
        "  print(\"--------Retrieval(vector store)-----------\")\n",
        "  question = state['question']\n",
        "  documents = retriever.invoke(question , search_kwargs = {'k':2})\n",
        "  combined_doc = \" \".join([item.page_content for item in documents])\n",
        "  print('Documnets retrieved')\n",
        "  return {'documents':combined_doc , 'question' : question}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIZmFVw75_zs"
      },
      "outputs": [],
      "source": [
        "# def wiki_search(state):\n",
        "#   print(\"--------Wiki Search-----------\")\n",
        "#   question = state['question']\n",
        "#   documents = wiki.run(question)\n",
        "#   wiki_result = Document(page_content = documents)\n",
        "#   return {'documents':wiki_result , 'question' : question}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1B0rZemN6Vx",
        "outputId": "f1e4a380-0307-4eaa-b2ac-f3ae693e045c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content='Nodes¶ In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id). Similar to NetworkX, you add these nodes to a graph using the add_node method:\\nLangGraph Nodes. Nodes are defined as Python functions that can perform a set of actions. For example, a node can integrate with a large language model, process information, call an external API, or any other task. A LangGraph node takes the state of the graph as a parameter and returns an updated state after it is executed.\\nNodes (Tasks): Nodes are like the workstations on the assembly line. Each node performs a specific task on the product. In LangGraph, nodes are Python functions that take the current state, do some work, and return an updated state. Next, we define the nodes, each representing a task in our sandwich-making process.\\nNodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making\\nIn LangGraph, each node represents an LLM agent, and the edges are the communication channels between these agents. This structure allows for clear and manageable workflows, where each agent performs specific tasks and passes information to other agents as needed. State management. One of LangGraph\\'s standout features is its automatic state')"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Document(page_content = string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl9eDpd4ARIp"
      },
      "outputs": [],
      "source": [
        "def google_search(state):\n",
        "  print(\"--------google_Search-----------\")\n",
        "  question = state['question']\n",
        "  result = search.invoke(question)\n",
        "  combined_result = '\\n'.join([item['content'] for item in result])\n",
        "  print('google_search')\n",
        "  return {'documents':combined_result , 'question' : question}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPGK51nT7SuE"
      },
      "outputs": [],
      "source": [
        "def router(state):\n",
        "  print(\"-------Routing the query--------\")\n",
        "  question = state['question']\n",
        "  source = Router.invoke({'query' : question})\n",
        "  if source.datasource == 'vector-database':\n",
        "    print(\"----------------Routing Query to Vector Store-----------\")\n",
        "    return 'vectorstore'\n",
        "  elif source.datasource == 'google-search':\n",
        "    print(\"----------------Routing Query to Google-----------\")\n",
        "    return 'google_search'\n",
        "  else:\n",
        "    print(\"----------------Routing Query to LLM-----------\")\n",
        "    return 'llm'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def llm(state):\n",
        "  print(\"--------llm-----------\")\n",
        "  documents = state['documents']\n",
        "  question = state['question']\n",
        "  output = llm.invoke({'context' :documents , 'question' : question})\n",
        "  return {'generation' : output }\n"
      ],
      "metadata": {
        "id": "3-Odm-6A7gE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT2t9qjmDDcJ"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1AyO3hiDnKS"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP8w3TMrDssY"
      },
      "outputs": [],
      "source": [
        "final_llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.3-70b-versatile\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHcLt0d-EaBh"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRxz4r2UDv-B"
      },
      "outputs": [],
      "source": [
        "llm_g = prompt | final_llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_rzqx4T_26A"
      },
      "outputs": [],
      "source": [
        "def generator(state):\n",
        "  print(\"--------Generation-----------\")\n",
        "  documents = state['documents']\n",
        "  question = state['question']\n",
        "  output = llm_g.invoke({'context' :documents , 'question' : question})\n",
        "  return {'generation' : output }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYvr0XdJ9Yay",
        "outputId": "059fab63-7528-47e8-c07c-11a93d6f75ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78a4411f76d0>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from langgraph.graph import StateGraph , START , END\n",
        "workflow = StateGraph(GraphState)\n",
        "##Defining the nodes\n",
        "workflow.add_node('google_search' , google_search )\n",
        "workflow.add_node('vectorstore' , vectorstore)\n",
        "workflow.add_node('generator' , generator)\n",
        "##Adding conditional edges\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    router,\n",
        "     {\n",
        "        'google_search':'google_search' ,\n",
        "        'vectorstore':'vectorstore'\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge('vectorstore','generator')\n",
        "workflow.add_edge('google_search','generator')\n",
        "workflow.add_edge('generator',END)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBsy_k2dEuFw"
      },
      "outputs": [],
      "source": [
        "app = workflow.compile(checkpointer= memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "_A_n-ZEiFwfi",
        "outputId": "86c50a2f-da9c-44c1-90cc-02c3e7914431"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image , display\n",
        "try :\n",
        "  display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx1wNysimBCC"
      },
      "outputs": [],
      "source": [
        "# from typing import Annotated\n",
        "\n",
        "# from typing_extensions import TypedDict\n",
        "\n",
        "# from langgraph.graph import StateGraph, START, END\n",
        "# from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "# class State(TypedDict):\n",
        "#     # Messages have the type \"list\". The `add_messages` function\n",
        "#     # in the annotation defines how this state key should be updated\n",
        "#     # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "#     messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "# graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUiWjURKmca2",
        "outputId": "e9b80d36-ea5d-4ba7-c620-bca0aa6e516f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7964d26af760>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from langchain_groq import ChatGroq\n",
        "# llm =  ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.3-70b-versatile\")\n",
        "# llm = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "# def chatbot(state: State):\n",
        "#     return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# # The first argument is the unique node name\n",
        "# # The second argument is the function or object that will be called whenever\n",
        "# # the node is used.\n",
        "# graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqOjcIIyq3KL",
        "outputId": "c6f8a3a7-590c-4db2-950f-ea0ab4cba4c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7964d26af760>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import json\n",
        "\n",
        "# from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "# class BasicToolNode:\n",
        "#     \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "#     def __init__(self, tools: list) -> None:\n",
        "#         self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "#     def __call__(self, inputs: dict):\n",
        "#         if messages := inputs.get(\"messages\", []):\n",
        "#             message = messages[-1]\n",
        "#         else:\n",
        "#             raise ValueError(\"No message found in input\")\n",
        "#         outputs = []\n",
        "#         for tool_call in message.tool_calls:\n",
        "#             tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "#                 tool_call[\"args\"]\n",
        "#             )\n",
        "#             outputs.append(\n",
        "#                 ToolMessage(\n",
        "#                     content=json.dumps(tool_result),\n",
        "#                     name=tool_call[\"name\"],\n",
        "#                     tool_call_id=tool_call[\"id\"],\n",
        "#                 )\n",
        "#             )\n",
        "#         return {\"messages\": outputs}\n",
        "\n",
        "\n",
        "# tool_node = BasicToolNode(tools=[tool])\n",
        "# graph_builder.add_node(\"tools\", tool_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D02ILe5yrFN0"
      },
      "outputs": [],
      "source": [
        "# def route_tools(\n",
        "#     state: State,\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     Use in the conditional_edge to route to the ToolNode if the last message\n",
        "#     has tool calls. Otherwise, route to the end.\n",
        "#     \"\"\"\n",
        "#     if isinstance(state, list):\n",
        "#         ai_message = state[-1]\n",
        "#     elif messages := state.get(\"messages\", []):\n",
        "#         ai_message = messages[-1]\n",
        "#     else:\n",
        "#         raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "#     if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "#         return \"tools\"\n",
        "#     return END\n",
        "\n",
        "\n",
        "# # The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
        "# # it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "# graph_builder.add_conditional_edges(\n",
        "#     \"chatbot\",\n",
        "#     route_tools,\n",
        "#     # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "#     # It defaults to the identity function, but if you\n",
        "#     # want to use a node named something else apart from \"tools\",\n",
        "#     # You can update the value of the dictionary to something else\n",
        "#     # e.g., \"tools\": \"my_tools\"\n",
        "#     {\"tools\": \"tools\", END: END},\n",
        "# )\n",
        "# # Any time a tool is called, we return to the chatbot to decide the next step\n",
        "# graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "# graph_builder.add_edge(START, \"chatbot\")\n",
        "# graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "tOYljnB0m1cv",
        "outputId": "04a7aa08-efd1-4d41-9242-e613a826df7e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANYAAAD5CAIAAADUe1yaAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XlYE9feB/AzScieAAk7kV0EBFdcQXEtda3Y1laxLq193G2va721ajdfa6v1tr3WtnrdsO4bWBVU1LrhjgooKgIKGAiEJCRkz7x/hIdSDJvNzJmQ83n6R80y54d+OTNz5swZDMdxgCDw0GAXgDg7FEEEMhRBBDIUQQQyFEEEMhRBBDIG7AJehUpuVFUZa1VmTY3JZHCMYSWGC0ZnYFwBnStkiH2ZbC4ddkVUgTnGPyAAAABZqa7grqYwV8MTMswmnCuk8wQMJocGHOEnYLAwdbWptsZcqzJplGaeKz04mtexG5/v7gK7NMgcI4LKKuOV1Eq6C+buxQzuzPPwZ8Gu6J8qLdAW5mjkUr2bJ7P/GDHDxXmPiBwggtdOVuXfrOk/1iOsKx92LfZ390/FlbSqAUke0f1dYdcCB9UjePA/JdFxwohYIexCiHU9XV4jNw6d6A27EAioG0Ecx39d/nTsTD/fYA7sWsiQd01VlKsZ+b4v7ELIRt0I/rz0yZQVQTyhQ56zv5qHN1Q5V1RvfSSBXQipKBrBgxtL4saJfYOcov9r6P5lZVWZftDbXrALIQ8VT8SyTlTFDBA6Yf4AADFxrlwB/cF1FexCyEO5CFZXGJ5kqzv1bOfnH83oMdT9/AEZ7CrIQ7kIXkmr6j9GDLsKmBgutJ7D3K+drIJdCEmoFUFpkY7FoYXEtMPxvzbpnSiSFumMBgvsQshArQgW3FOLfJikNZeTk6PX62F9vXlsHr0wR0PQximFWhEszNUEd+aR01ZaWtq0adO0Wi2Ur7coOJqHIki26gqDUMRw9yapF3zlDsw6jEVc/2cVEsNTVhkJbYIiKBRBZaURwzAitlxcXDxr1qz4+PiRI0euWbPGYrGkpaWtXbsWADBs2LDY2Ni0tDQAQHZ29rx58+Lj4+Pj42fOnPngwQPr1xUKRWxs7K5du1asWBEfH//hhx/a/Lp9MVxoaoVJozTZfctUQ6FrD7UqM1dIyCy6L7/8sqioaNGiRRqN5ubNmzQaLS4ubvLkySkpKRs3buTz+QEBAQCAsrIyvV4/Y8YMGo124MCBBQsWpKWlsdls60a2bt369ttvb968mU6ne3t7v/x1u+MJGRqViedKoX8jIlDox9OoTARdjisrK4uIiEhKSgIATJ48GQAgEokkEgkAIDo62s3NzfqxESNGjBw50vr/UVFRs2bNys7O7tu3r/WVmJiYuXPn1m/z5a/bHc+VrlGaQQeCNk8VFIogADiDRciOeOTIkdu3b1+3bt2MGTNEIlFTH8Mw7Ny5cykpKYWFhVwuFwBQVfXX4Fzv3r2JqK0ZLDYdt1Dx8ql9UehYkMNj1MgJOfSZO3fuwoULMzIyxo4du3///qY+tmXLliVLlkRFRW3YsOHjjz8GAFgsf43McThkXzBUVBq4TjBLg0IR5ArptSozEVvGMGzSpEnHjh1LSEhYt25ddnZ2/Vv1szT0ev22bdvGjRu3aNGibt26xcTEtGbLhE7yIO7gmFIoFEGByMWFmB2xdQCFx+PNmjULAPDw4cP6Xk0mq7saq9Vq9Xp9ZGSk9Y8KhaJRL9hIo68TQSBiCNzafy9IoZ/Q059V+kSrVpj49v57X7ZsGZ/P79u376VLlwAA1px17dqVTqd/9913Y8eO1ev1b775ZlhY2N69e8VisVqt/vXXX2k02pMnT5ra5stft2/NRXkaFyYNoxHyO0kp9NWrV8Ou4S8KmdGos3gFsO272ZKSkkuXLp06dUqr1c6fP3/QoEEAAKFQ6O3tffr06YsXL6pUqtGjR/fo0ePy5cv79+8vLi6eP39+YGDgoUOHkpOTjUbjzp074+Pjo6Ki6rf58tftW/Odcwr/MI5XBzv/VVAQtaasPnuoeZqjGfSWE03YbErar2WDJ3jy3dr/LZ4U2hEDAAIieNdOyqXFOp9A27/9CoVi3LhxNt+SSCQlJSUvv56QkPD555/bu9LGZsyYYXOvHRkZWX+VpaGePXuuX7++qa3lXFHy3RjOkD/K9YIAgNIn2munqsbPs33/hNlsLi8vt/kWhtn+WTgcjru7u73LbEwmkxmNNi7pNlUVi8USi5ucFvnr8qdTVwayOO3/dJiKEQQAnNtf0bE7X9KRC7sQOO5fVhp0lp5DCf+1oQgKDcrUGzzB69QOqVZNyBghxT3Lr316T+08+aNoBAEAE5cG/P7NM9hVkK2m2ng6pfyN2f6wCyEVFXfEVnqteffaZ8mfBDjJIVF5sS4jpTx5eQDNCcYCG6JuBK29wp51z8fO9PVp7zd05t9S3f1TOeFf7X1WjC2UjqDV2T3lWo05bowHaROqyVTyuPZyWpUkjBM31gN2LXA4QAQBAIU5mstplSExPO8AdnA0rx3sqnQac2Gu5kWhTllpjBsjtvsFIQfiGBG0enyn5vEddWGOJrKPkMHEeEIGz5XOYtMd4geg0zGNylSrMqmVJpXcVF6sC+7MC+8pCOjkpGNP9RwpgvWKHmiUFUaNyqRRmk0mi8WuozdGozEvL69r16723CgAHD4dt+BcIYPvyhD7Mv1C2/nRbes5ZAQJVVVVNXHixIyMDNiFOAuKjgsizgNFEIEMRbAxDMPCw8NhV+FEUAQbw3H80aNHsKtwIiiCjWEY5urqpIvfQ4Ei2BiO40qlEnYVTgRF0AYfHx/YJTgRFEEbpFIp7BKcCIpgYxiGNbxTDiEaimBjOI7n5eXBrsKJoAgikKEINoZhWDOrbyF2hyLYGI7jcrkcdhVOBEXQBg8PJ53ADAWKoA2VlZWwS3AiKIIIZCiCjWEYFhoaCrsKJ4Ii2BiO4wUFBbCrcCIogghkKII21C/3i5AARdAGmysCIgRBEUQgQxFsDM2UIRmKYGNopgzJUAQRyFAEG0M3cZIMRbAxdBMnyVAEEchQBBtD9xGTDEWwMXQfMclQBBtDM2VIhiLYGJopQzIUQQQyFEEbvL29YZfgRFAEbWjqSYsIEVAEbUDzBcmEImgDmi9IJhTBxtBkLZKhCDaGJmuRDEXQBonE9jPhESKgR9/U+eCDD6RSKZ1Ot1gs1dXVIpEIwzCTyXTixAnYpbVzqBesM2HChJqamrKyMqlUqtfrX7x4UVZWhmEO/7xF6kMRrJOYmBgSEtLwFRzHe/bsCa8iZ4Ei+JeJEydyuX89F9PHx2fSpElQK3IKKIJ/SUxMDAwMtP6/tQuMiIiAXVT7hyL4N1OmTOHxeNYucOLEibDLcQoogn8zfPjwwMBAHMe7d++OLtORgwG7gBboNObKMoNBbyGtxXGvzQS1R18fOPVpjoa0Rrk8usjPhcmik9YidVB3XNBswjNSpCWPtJJwnpHECEJh1Fvk5bqwboLBb3vBroVsFI2gXms+9ENpz0QPv2BuKz7eTjy4rigv0o750Bd2IaSiaAR3rSke/I6vqwcTdiFke5KtkhbWjpjmRA/Bo+LpSG6WMiiK74T5AwCEdRPiFlD2VAu7EPJQMYIVz/QcAdXPk4jjwqJVvTDAroI8VIygQWcRilxgVwGNmw9LozTBroI8VIygrtZiNsMuAh6zATcZqXiAThAqRhBxKiiCCGQogghkKIIIZCiCCGQogghkKIIIZCiCCGQogghkKIIIZCiCCGTtOYKPn+QPHhp79erFNn3LbDbfv5/d8JUVKxfNnDW5ra2/vB3EpvYcwVfz7fovN2xcQ53ttHsogo0Z9HpKbafdayczQ3U63a6ULefOZcgqK7y9fV8bPip50nTrW4VFBXv378zPz5NIAj6avywmphsAoKKifOu2TdeuXdZo1B06BE6aOH3Y0NcBAGvXrT53/jQAYPDQWADA77tTfX38AACaWs2q1Utv37nOZLKGDnn9g/fnsFgsAIDJZNq2fXN6xnGlUhEYGDxt6sz4uEEvb+fg/lNisQfsvySKag8RNJvN//704/s52eOT3g0LDS8qfvq8pJhOr7shMmX31glvvzfi9bG/79n+6WcLf09J5fP5JrPp4cPcN8a+5Sp0+/NS5tdrVvj7d4iM6Dx50vuyivIXL0qXf/IFAEAsqstNefmLfn0HzJ2z6MaNqwcO7i4te/71lxsAAN+t/+rM2ZOTk98PCgo9c/bkZysX/+f737p06d5oO66ublD/hiitPUTwwp9n72TfXLL4s5Ej3nj53Y/mL0tMHA0ACAwInjNv2q3b1xIGDvXz9d/+vwPWhbNGjHgj6c1hly+fj4zoLJEEuLq6yaurrJ1lvZDgsLlzFgIAXk8c4+Hhtf9Ayt27t93dRekZx6e8N2Pa1JkAgISBQydPSdq+45cN6zc3tR3kZe0hgtdvXGGxWImvjbb5rlBY90C5oKBQAIBMVrea/pOCR9t3/JKfn2ftR+XyqlY2lzTunf0HUu5k37TuW+PjB1tfxzCsV2zf02fQeoRt0x5OR6rlVR5iz/o9b1NoNJo1bQCA23duzJk71WgwLF2y6vNV64RCVwve2rvlPTw8AQAajVqjUQMA3N1E9W8Jha61tbUaDXnLMLQD7aEX5PMF8urW9mFWu3Zt8fOTrPl6I4PBAABw2JyG7zZ/b7VCUQ0AcHcXeXh4AQBUKqU1lAAAubyKwWCw2ezWbAexag+9YPfuvbRa7dnM9PpXTKYW7kBTqhRhoeHW/BkMhlptrcVS1wuy2Ry5vKr+jy+7cOEMAKBHj96RkdEYhmVdu2R93WAwZF271LlzF2t/3OJ2EKv20AsOHzby6LH9a79Z9fBhblho+NPCJ7duX/t18+5mvtKtW2x6etqJk8eEAtcDh3bX1KiKCgtwHMcwrGuXHidPpW74fk1MdDeBQNi//0AAQMHTx//dtCE0tGN+fl7a8cMJA4dGdIoCACS+Nnr7jl/MZrOfn+SPP47I5VX/Xv6ltYmG2/Hzk6Dzkqa0hwiyWKz1323+7bcfT585cfyPwz4+foMHvdZ8R/j+tNnyqsoff/pWIBCOHjV+wluTN2xccyf7Zo/uvYYPH5n/KC/j9B9Xsy6+njjGGsGJ707Nybl7/I/DPB7/7beSp0+bZd3Oxx99wuPxjxzdV1OjCg4KXfPV9z2697K+1XA7U977EEWwKVRcU+bY5rLwWDdJRyda0Kih3CsKk8EU/4azDGW3h2NBxKGhCCKQoQgikKEIIpChCCKQoQgikKEIIpChCCKQoQgikKEIIpChCCKQoQgikKEIIpBRcbKWUOxCo1Fu/g5p6AzMqZ6HSMVekMOjyUqc9z5waVGtUOxEj12hYgQDI7mqSid6/FAjWrU5IJzTig+2E1SMoG8wR+zHvJJaAbsQCE6nlPYc6sbkONGOmIqzpq1uZ1aXPdX5d+R5+rMZTCr+qtiRTm2qkurvX6oe8o5XQCfnmi5O3QgCAJ7la/JvqmtrzNXlf9svm81mo9FYf6+kfeE4rtPpOBySdoVarZbFYglFLE8Js/sgN6c6CqyDO6D58+cTt/GNGzfGx8enpqYS10RDFRUVK1euJKctaqJ0L/iyzMzMIUOGELf9Fy9ezJ8/v6ioKDIycteuXcQ19LKdO3cOHTrU39+fzEapwJGOsd555x2i/4UOHDhQVFQEAHj27Nnx48cJbauRkSNHzp49W+98qxI6Ri8olUpdXV1LS0vDwsKIa6W0tHTBggXFxcXWP5LfEVoPDe/duxcVFSUQCEhuGhYH6AUPHDiQlZXF4XAIzR8A4MiRI/X5AwAUFxcfO3aM0BZfxuFwOnbsOGbMGLVaTXLTsDhABIuLi8eNG0d0K2VlZefOnWv4ikaj2b27uVVBCCISic6fP6/T6aRSKfmtk4/SEbxy5QoAYPHixSS0tXfvXmsXWL8QEYZhz58/J6Fpmzw8PPh8flxcXMOOuX2CfUpum8Fg6N+/f3V1NflNy2Sy1157jfx2bdJqtdu2bYNdBbGo2AsqFIri4uKzZ8+6uUFYotlsNkdERJDfrk1sNnvatGkAgE8//dS6OGf7Q7kIpqamFhUVhYWFEXTxo0VGo9E6LkMp06dP//jjj2FXQQhqRVAmk925c6dbN5jroGm1Wm9vb4gF2BQWFvbjjz8CAM6fPw+7FjujUASLioowDFu1ahXcMqqqqlxcqHuh1mg0Ll26FHYV9kSVCK5cuZLD4Xh4wF9Ur7q6OiAgAHYVTRo+fPioUaNas5ixo6BEBEtKSvr06UOR3V9hYSEVfhOakZCQAADYt2/fo0ePYNdiB/AjqNVq+Xy+9TebCvR6fWhoKOwqWpacnLxq1ap2cJoMOYJLliy5evUqlMGXpmRmZoaHh8OuolX27NljMpny8/NhF/KPwIzgrVu3FixYQOjkq7ZSKBRCodDPzw92Ia3FYrHkcvnOnTthF/LqoEVQLpd37NixQ4cOsAqwKSsrKygoCHYVbdOvX7/q6mrYVbw6OBE8ePDgL7/8IhQKobTejD///HPgwIGwq2izjz76yGAwOOhcQwgRlEqlbm5uy5cvJ7/pFimVSkeMIACAyWRu2rQpJSUFdiFt5hhTVsmRnp5+4cKFNWvWwC7k1V27ds3Dw8Mhzujrkd0Lzps3Lycnh+RGW+nIkSNJSUmwq/hH+vTpExgY6FgPviM1ghcuXBgzZkx0dDSZjbZSYWEhg8Ho1asX7EL+KQaDMXz4cIVCAbuQ1kI74jqLFy8eNWrU4MGDYRdiB0ql8vjx48nJybALaRXyesF9+/ZRdhf88OHDFy9etI/8AQBcXV0dJX/kRbCoqGj//v3U3AUDAL7//ntybg8g05IlS+7evQu7ipaRFEEMw7Zs2UJOW2119OhRiUTSvXt32IXY2ZIlS3744QfYVbTM2Y8FTSZTYmLi2bNnYRfivMjoBTMzM7/44gsSGnoFCxcupGxtdpGRkQG7hBaQEcGsrKx+/fqR0FBb7dq1KyQkJC4uDnYhBHr06NG2bdtgV9Ec590RP378+Mcff3SIo6V/wmQypaWlUXnInYwIGgwGJpNJdCtt1bt376tXr9LpTrSeKTURviPOzc2dMWMG0a201eTJk3fs2OEk+cvJydm0aRPsKppEeATVajXRyxG11U8//ZScnBwZGQm7EJJER0fv3r1bp9PBLsQ2pzsW3LJli9FonD17NuxCSFVSUsLj8dzd3WEXYgPhvaDJZDIYqPIEh9TU1NLSUmfLHwBAIpFQM39kRDAzMxP63elWN27cyM3NpUgxJKuoqJgzZw7sKmwj/AFgYrGYCtPX7t27t2nTJoqPkBHHy8srPz9foVBQ6mZFK6c4FiwoKFi+fPn+/fthFwKTxWLBMAzDMNiFNNb+xwVLSkoWLFhw+PBhWAUgzSPjAl1SUhKsNWsfP348Z84clD/rqdjPP/8MuwobyHgY7KBBg6ZOnWo2m1UqlZeXF2kPU3j48OHevXtTU1PJaY7iBAJBQUEB7CpsIDCCAwcOrK2tta4lbD0EwXE8KiqKuBYbKigo+PTTTw8dOkROc9Q3YMCArl27wq7CBgJ3xEOGDKHRaNb5qtZXWCxWnz59iGuxXk5Ozm+//Yby1xCDwRCJRLCrsIHACK5evToqKqrh6Y6npycJv4jZ2dnffvvt2rVriW7IschkstGjR8OuwgZiT0e++eab+iVacBzncrlEXy++ePHi8ePHd+zYQWgrjojJZFqPi6iG2Ah6e3v/61//sq4YiWEY0V1genr6oUOHVqxYQWgrDkooFFLz9h3CB2Xi4+PHjx/P4/H4fD6hB4JHjx69cOHCxo0biWvCoWEYFhISArsKG1p1RmwyWrTqV7/INvHt94sLKgoKCkICOtdUE7JC8rlz53LvP3Xo5WCIZjQa33rrLfKfqteiFq6OPLiuundRKZcaOPx/NLuzflyGIAaDwcufX1ZQG9KF32u4u9iPRVxbjmXJkiVnz56tHxSzdoc4jt++fRt2aXWa6wWvZ8gry4wDxvsIRNR9CEJDFjOukBlObJcOm+TtGwTnyTlUM3v27Ly8vPLy8oajY5RaxrPJY8Frp+RKmWlAkrej5A8AQKNjIh/WuLmBZ/dUlD+j6CRhkoWEhPTs2bPhvg7DMEqtoWg7gtUVhspSfd/RXqTXYx9DJvrezHDgtW/ta8qUKQ0fqCGRSN59912oFf2N7QhWlupxnHKzelpP4O7y/HGtQQ9/niIVhIWF9e7d2/r/OI4PGDCAIo94sbIdQbXS7NnBsY+lAqN48hcOufYyEd577z0vLy8AgL+/P9UW3bIdQaPeYtQ5dheiqjIB4MAduX2Fhob26dMHx/GEhARKdYEkTdZC2spiwZ89rFVXmzQqk8mIazV2eMRSV7/Juu4dO4nizuwp/+dbY3PoTA6NK6QL3V0CIrj/ZFMogtTy4Loq/5a65HGtX7jQZMDpLnSaCwNg9hiUoLF79xtltACjPS4U16hxs9FkNhldXPSpv5QFRvHCu/M7xQpeYVMoglSRd0116VilZ4CAwRNED6fWvrJ57oGimora3Fu6y2lVA8aJO3ZvWxBRBOHTqs0ntpUbzbSQPhIG0/HWGMEwTOjNA4DH9xTezJQ/uKEe9YEPnd7aA3H4T+J0cs/yNTu/Lub7i3w6eTpi/hpichi+UV5Md7fNSwsqnrf20gCKIEzlz3UXDss7DQxkcRzmElSL2Hxm52HBJ7aVq6patYoGiiA0hbnqjBRZh24O89TPNgnqJTm8SSotbrkvRBGEQ60wnd3TbvNnFRTrf/jHUpOxhQFmFEE4Tu0sD+rtD7sKwoX29fvjfy0MQ6IIQnDzdLUZMBkujn3y0RosHlOjwXKvKpv5DIogBFknqrzCKLrUmt15hYgup8mb+YA9I5j3IOcfPpX5/IUzg4fGPntWZL+iKOfWGbl/lIiCywsBAL5YN/rgMTvf/Mpg0cUBgpwrTXaEdovgqfS0ufOm6XRae22wvXpwQ812dexZSG3F4rMf3lQ39a7dIuigT6UnmUpu1GksHIFz3drCF3Nkz3XGJqZv2ucC3an0tI3/WQsAGDd+GABg2dJVryeOAQBkZPyxe8+2srISsdhj1Mik5EnTrUt8mEymbds3p2ccVyoVgYHB06bOjI8b9PJms7Iu/brlx7KyEh8fv7Fj3hqf9I5dqoXoeX6tu4RP0MafPL114vSmMukjAV8UFhw7YvhsocADALDi66FvjlmW8+B8Xv5lDpvft1fSa4PrnoFgNpvPnN+adfOowaANDelpNBJ1t4NHkKD4QW1YNxs/u316wT694ya8PRkA8H9fb/xh45Y+veMAAOnpx//vm1UdO0Z8tmLNoITh/9v28+7f6xY5/W79V/v27xo9KunTf3/l4+P32crF9+7dabTN2tra1V8sY7owFy1c0b/fwKoqmV1KhavyhRHHCTkFfFxw47edC7y9gieM+3Rg/0lPi+5s3jbXYKiL1N7Dn/v5hM/5YHOPriMyMn/Ly79sff3I8W9Pn98aEd4/afRipgtbq6shojYAgNmMVctsXyyxTy/o7i7y85MAACIjo11d3awTxLf8778xMd1W/PsrAMDAAUNqalR79+14c/zEysqK9IzjU96bMW3qTABAwsChk6ckbd/xy4b1mxtus1oh1+v1AwYMGT5shF2KpAKN0sRgcYjY8tE/1veNTUoaXfdI2/CwPt/+8E7+k6yYqEEAgN49xg5NmAYA8PMJv37r2KMnWVGd4krKHmbdPDI0YfqIYbMAALHdRxUUEnVnpwuLoW7iFnKiZsqUlDyrrJS9M+G9+ld69ep34uSxktJn+fl5AID4+LrnT2MY1iu27+kzJxptwc/Xv3PnLim7t7LZnDGjx1Pw+U2vQKs2s9ztPxwor35RLiuslD/Punm04esKZd2wMJNZl3s6ne4q9FKqZACA+3nnAQAD+0+s/zyGETVIx2DRalXkRlCtUQMA3Nz+Wk1MIBACACplFRqNGgDg3uAtodC1trZWo9E03AKGYWvX/LBl60+bf9l44GDK8mVfdO3ag6BqSUPQqso16ioAwPDBM7pE/e3B8gKBx8sfptEYFosZAKBQSNlsPo/rSkhNjeCYpYmf3c6pr79f1cvTGwCgVCrq36qulluD6OHhBQBQqf4aKJLLqxgMBpvdeKiCz+d//NEnO7Yf4vH4Kz5bSM2FodqE50o36e0wC78RDlsAADAa9V6eQQ3/47CbO/Xh8dx1OrXRRMZTYUx6k8Dddn9ntwhy2BwAQGVl3UmDWOzh4+17/frl+g9cuHCGzWaHhXWKjIzGMCzr2iXr6waDIevapc6du9DpdKYLs2E6rQM9fr7+45PeVWvUUmmZvaqFReDKMBnsH0FPjwA3V58bt9P0hrpxWbPZZDIZm/+WxD8CAHDnXrrd63mZyWAWuNmOIH316tUvv1paoDWbgE9QGw6c2RzusdQDRcVPMYDlPbjfqVOUgC/cdyBFJis3Go2Hj+w9c/Zk8qT3e8X2FQqEUumLI0f3AYBVVsp+/vn7wqKCJYtX+vr6M1xcjhzd9zA/NyAgyEPsOWXa+MpKWVVV5ZGj+wx6/Qfvz2EwWnvk8PiOKiiSy2/ix4ZFrTRWSU0cNzufkWAY5u7me/1Wat7DizjAi5/fP3J8vdlsCOwQAwDIvLhT4hfRKaxuWbOsG0fZbF73Lq95eQTfyz17684JrU6t1lRfvXGkoPCmxC8yKiLevuUBAHRKTXAUW+Rt44DebhEUCoSent7nz5++evViTY0qMXF0WFi4u7so81zGyVOpimr5pEnTJye/b70w1Su2n0ajPnnqWGZmOo/LW7xoRa9e/QAAAr7A18fv9p0bNIwWGRVTUvLs0uVzFy9lisWenyxd7e8vaX091IwgV8i4/kelOND+h1/enkES/6inRdm3sk88K8n19Q3r2W2EdVywqQjSaLTI8HhZZfG93LNPi7J9vELk1WXensFERLDwVvmwZG8azcZlSdsra11Plxt0oOsgKi5N3EontpYkjPfwod7iRr+ve+4WIOa6OtEFkprKWpOqJmmu7cmR1OoknEFUX/6TXG0zEXz05PrOfctffp04rLhKAAACv0lEQVTDFjQ1dDw6cX7f2HH2qvBB/uXdB1e+/DqO4wDgNgduZk3/r8QvoqkN6tX6zr15Tb2LIki2bgPdrx4vcJcI6Qzb54JBAV0Wztn18us4DpqaXsPl2HPPHhrc02YBFosFx3GbzxEXCjyb2ppBa1RJ1ZG9mlxODkUQgrgx4rxbcp9ONgbtAABMJlvEhDmh374FVD6tHjBO3MwH0JRVCLoMcOOwzXptC4Mm7YCuRu8mxpq/uR1FEI4R032eZpXCroJYFgv+9HrZyOk+zX8MRRAOJos2brZf4fX2nMKnWSUTlwa0+DEUQWh8gznj5/kUXi+BXYj9mU2Wx5efTVomcfdqeXIJiiBMrmLmmBk+ORmFWlX7WRlbU617fOnZOwslXH6rTnZRBCHz8GfN3RBqUatKc8r1GjJmDBBHq9I/v/vCxaKe9U2osNWr5KNBGfgwDBv1gW9hjubPIxVcNzaDyxJ6cumOc5exSW9WyTRmvcGo0Q8a79EhvG0rXqIIUkVwNC84mldwX/34jubJZblIwjXqLXQmg8FiUHDFYhzHzXqT2WhyYdKqpdrgaF7HOH5Q1Kssi4giSC2hMfzQGD4A4EWhVqM0a5Qmg96is8dCv/bF4tLYXCZXyBW4070DWhh2aR6KIEX5BhNyiwkF2Y4gk41ZqNf5t4mrpwthN0Ig9mT7X0ng7iIrdux1EQrvqcW+7eGOp3bPdgS9OrAoueZJaylkhqDOXIYL6gYdQJO9oH8Y+89DUtLrsY+zu8v6jmxudgZCHc09jzj3qvJxtrprgtjdm9nU5DZK0apNykrjnwelb873d2vFpSGEClp4JHZhrib7gkJaqKMzqL5jFvmylDJDSDS39wgxT4jO9B1GCxGsp9dS/ZF0OA7YXAfoqpFGWhtBBCEI6jYQyFAEEchQBBHIUAQRyFAEEchQBBHI/h9Zsek9tetkAQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from IPython.display import Image, display\n",
        "\n",
        "# try:\n",
        "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "# except Exception:\n",
        "#     # This requires some extra dependencies and is optional\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBJc4pO6g5KJ",
        "outputId": "e50ad3fd-9ffd-485e-b3e7-10c0ae2b8a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------Routing the query--------\n",
            "----------------Routing Query to Vector Store-----------\n",
            "--------Retrieval(vector store)-----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Documnets retrieved\n",
            "{'vectorstore': {'documents': \"Benefits of Axis Max Life Smart Total Elite Protection Term PlanAxis Max Life Smart Total Elite Protection Term Plan offers various benefits that enhance the base coverage offered by the product. The following are some of the key benefits of this plan:1. Death BenefitOn the death of the life insured during the term of the policy, provided the policy is in-force, the insurer will pay the Guaranteed Death Benefit to the beneficiary under the Plan, which is the higher of:\\n\\na. For Single Pay - 1.25 times the Single Premium plus underwriting extra premium if any; For Other Premium Payment Term - 10 times the Annualised Premium* plus underwriting extra premium, if any,\\nb. 105% of Total Premiums paid^ plus underwriting extra premium plus loadings for modal premiums as on the date of death\\nc. Base Sum Assured#\\n\\n\\xa0* 'Annualised Premium' shall be the premium amount payable in a year excluding taxes, rider premiums, underwriting extra premiums and loadings for modal premiums. The Annualised premium remains same irrespective of the premium payment mode.\\n\\xa0^ 'Total Premiums Paid' means total of all the premiums paid under the base product, excluding any extra premium and taxes, if collected explicitly.\\n'Sum Assured on Death' means an absolute amount of benefit which is guaranteed to become payable on death of the life assured in accordance with the terms and conditions of the policy.\\n# 'Sum Assured on Death' is the base sum assured.\\nThe details of benefits under this product are given below:\\n\\nGuaranteed Death Benefit is payable on death of the Life Insured, provided the policy is in-force.\\nAccelerated Benefit capped at Rs 1 crore is payable on diagnosis of Terminal Illness, provided the policy is in-force.\\n\\n\\nBase CoverSize of BenefitsALife Cover\\n\\n            Guaranteed Death Benefit will be paid to the beneficiary on death of the Life Insured. \\n            In case Terminal Illness (TI) Benefit claim has been paid, the Guaranteed Death Benefit amount shall be reduced to the extent of the claim paid out on account of TI Benefit. Benefits of Axis Max Life Smart Total Elite Protection Term PlanAxis Max Life Smart Total Elite Protection Term Plan offers various benefits that enhance the base coverage offered by the product. The following are some of the key benefits of this plan:1. Death BenefitOn the death of the life insured during the term of the policy, provided the policy is in-force, the insurer will pay the Guaranteed Death Benefit to the beneficiary under the Plan, which is the higher of:\\n\\na. For Single Pay - 1.25 times the Single Premium plus underwriting extra premium if any; For Other Premium Payment Term - 10 times the Annualised Premium* plus underwriting extra premium, if any,\\nb. 105% of Total Premiums paid^ plus underwriting extra premium plus loadings for modal premiums as on the date of death\\nc. Base Sum Assured#\\n\\n\\xa0* 'Annualised Premium' shall be the premium amount payable in a year excluding taxes, rider premiums, underwriting extra premiums and loadings for modal premiums. The Annualised premium remains same irrespective of the premium payment mode.\\n\\xa0^ 'Total Premiums Paid' means total of all the premiums paid under the base product, excluding any extra premium and taxes, if collected explicitly.\\n'Sum Assured on Death' means an absolute amount of benefit which is guaranteed to become payable on death of the life assured in accordance with the terms and conditions of the policy.\\n# 'Sum Assured on Death' is the base sum assured.\\nThe details of benefits under this product are given below:\\n\\nGuaranteed Death Benefit is payable on death of the Life Insured, provided the policy is in-force.\\nAccelerated Benefit capped at Rs 1 crore is payable on diagnosis of Terminal Illness, provided the policy is in-force.\\n\\n\\nBase CoverSize of BenefitsALife Cover\\n\\n            Guaranteed Death Benefit will be paid to the beneficiary on death of the Life Insured. \\n            In case Terminal Illness (TI) Benefit claim has been paid, the Guaranteed Death Benefit amount shall be reduced to the extent of the claim paid out on account of TI Benefit. Benefits of Axis Max Life Smart Total Elite Protection Term PlanAxis Max Life Smart Total Elite Protection Term Plan offers various benefits that enhance the base coverage offered by the product. The following are some of the key benefits of this plan:1. Death BenefitOn the death of the life insured during the term of the policy, provided the policy is in-force, the insurer will pay the Guaranteed Death Benefit to the beneficiary under the Plan, which is the higher of:\\n\\na. For Single Pay - 1.25 times the Single Premium plus underwriting extra premium if any; For Other Premium Payment Term - 10 times the Annualised Premium* plus underwriting extra premium, if any,\\nb. 105% of Total Premiums paid^ plus underwriting extra premium plus loadings for modal premiums as on the date of death\\nc. Base Sum Assured#\\n\\n\\xa0* 'Annualised Premium' shall be the premium amount payable in a year excluding taxes, rider premiums, underwriting extra premiums and loadings for modal premiums. The Annualised premium remains same irrespective of the premium payment mode.\\n\\xa0^ 'Total Premiums Paid' means total of all the premiums paid under the base product, excluding any extra premium and taxes, if collected explicitly.\\n'Sum Assured on Death' means an absolute amount of benefit which is guaranteed to become payable on death of the life assured in accordance with the terms and conditions of the policy.\\n# 'Sum Assured on Death' is the base sum assured.\\nThe details of benefits under this product are given below:\\n\\nGuaranteed Death Benefit is payable on death of the Life Insured, provided the policy is in-force.\\nAccelerated Benefit capped at Rs 1 crore is payable on diagnosis of Terminal Illness, provided the policy is in-force.\\n\\n\\nBase CoverSize of BenefitsALife Cover\\n\\n            Guaranteed Death Benefit will be paid to the beneficiary on death of the Life Insured. \\n            In case Terminal Illness (TI) Benefit claim has been paid, the Guaranteed Death Benefit amount shall be reduced to the extent of the claim paid out on account of TI Benefit. Axis Max Life Smart Secure Plus Plan offers two death benefits. The Smart Secure Plus Plan is designed to fulfil your financial security requirements and provide a dependable support system for emergencies. You also get inbuilt benefits such as cover for terminal illness and a special exit value*.\\nThis term plan also offers an array of optional benefits such as joint life cover, premium breaks, additional payout on accidental death and more. With this plan, your insurance needs are completely covered. It can work as a one-stop solution for your financial security requirements. As the policy buyer, it is best to understand how the policy works to be more aware of your financial decisions.\\n(*This is only applicable for NROP (Pure Protection), Policy Term 40 and above)Axis Max Life Smart Secure Plus PlanA plan that provides comprehensive financial protection.A plan that provides comprehensive financial protection.Based on 22643 usersPLAN BENEFITS₹ 1 CrLife Cover64Critical Illness Cover₹ 46K*Tax SavingsReturn of Premium : Get back all premiums paid on survival till maturityLimited pay option : Pay premium till 60 years for a life cover till 85 years@₹987/Month~Buy NowDisclaimers:\\n~This is applicable for a 24-Year Old Healthy Male, Non-Smoker, 25 Years Policy Term, 25 Year Premium Payment Term (exclusive of GST) for Axis Max Life Smart Secure Plus Plan.\\n*Tax benefits as per prevailing tax laws, subject to change. Save Rs. 46,800 on taxes if the insurance premium amount is Rs.1.5 lakh per annum and you are a regular Individual, falling under 30% income tax slab having taxable income less than Rs. 50 lakh and Opt for Old tax regime.\", 'question': 'tell me something about the insurance plans your company Max life insurance offers'}}\n",
            "--------Generation-----------\n",
            "{'generator': {'generation': \"At Max Life Insurance, we offer a range of comprehensive insurance plans to cater to the diverse needs of our customers. Two of our notable plans are the Axis Max Life Smart Total Elite Protection Term Plan and the Axis Max Life Smart Secure Plus Plan.\\n\\nThe Axis Max Life Smart Total Elite Protection Term Plan provides a Guaranteed Death Benefit to the beneficiary in the event of the life insured's death, which is the higher of 1.25 times the Single Premium, 10 times the Annualised Premium, 105% of Total Premiums paid, or the Base Sum Assured. Additionally, it offers an Accelerated Benefit of up to Rs 1 crore in the event of a Terminal Illness diagnosis.\\n\\nOn the other hand, the Axis Max Life Smart Secure Plus Plan is designed to provide comprehensive financial protection and offers a range of benefits, including a life cover of up to Rs 1 crore, critical illness cover, tax savings, and a return of premium on survival till maturity. The plan also offers a limited pay option, where you can pay premiums till the age of 60 for a life cover till 85 years.\\n\\nBoth plans are designed to provide financial security and protection to our customers, and we offer various optional benefits and features to customize the plans according to their individual needs.\"}}\n"
          ]
        }
      ],
      "source": [
        "events = app.stream({'question' : 'tell me something about the insurance plans your company Max life insurance offers'} , {\"configurable\": {\"thread_id\": '2' }} )\n",
        "for event in events:\n",
        "  print(event)\n",
        "  if \"generator\" in event:  # Check if the event contains the generation key\n",
        "        s = event[\"generator\"][\"generation\"]  # Extract the generation part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "w3AGNsqkh-44",
        "outputId": "e525d90f-0264-4a18-ebc6-0ee11e886c4c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"At Max Life Insurance, we offer a range of comprehensive insurance plans to cater to the diverse needs of our customers. Two of our notable plans are the Axis Max Life Smart Total Elite Protection Term Plan and the Axis Max Life Smart Secure Plus Plan.\\n\\nThe Axis Max Life Smart Total Elite Protection Term Plan provides a Guaranteed Death Benefit to the beneficiary in the event of the life insured's death, which is the higher of 1.25 times the Single Premium, 10 times the Annualised Premium, 105% of Total Premiums paid, or the Base Sum Assured. Additionally, it offers an Accelerated Benefit of up to Rs 1 crore in the event of a Terminal Illness diagnosis.\\n\\nOn the other hand, the Axis Max Life Smart Secure Plus Plan is designed to provide comprehensive financial protection and offers a range of benefits, including a life cover of up to Rs 1 crore, critical illness cover, tax savings, and a return of premium on survival till maturity. The plan also offers a limited pay option, where you can pay premiums till the age of 60 for a life cover till 85 years.\\n\\nBoth plans are designed to provide financial security and protection to our customers, and we offer various optional benefits and features to customize the plans according to their individual needs.\""
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "bRFSPkc7gZ20",
        "outputId": "81f312b9-9573-41a9-a004-6b00e0e8f6bf"
      },
      "outputs": [
        {
          "ename": "InvalidUpdateError",
          "evalue": "Must write to at least one of ['documents', 'question', 'generation']",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-608b2111e2ac>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# print(event , 'break')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1661\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 )\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/write.py\u001b[0m in \u001b[0;36m_write\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         ]\n\u001b[0;32m---> 96\u001b[0;31m         self.do_write(\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/write.py\u001b[0m in \u001b[0;36mdo_write\u001b[0;34m(config, writes, require_at_least_one_of)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequire_at_least_one_of\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mchan\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequire_at_least_one_of\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 raise InvalidUpdateError(\n\u001b[0m\u001b[1;32m    158\u001b[0m                     \u001b[0;34mf\"Must write to at least one of {require_at_least_one_of}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 )\n",
            "\u001b[0;31mInvalidUpdateError\u001b[0m: Must write to at least one of ['documents', 'question', 'generation']"
          ]
        }
      ],
      "source": [
        "events = app.stream(\n",
        "  {\"messages\": [(\"user\", 'tell me something about the insurance plans your company Max life insurance offers')]}, {\"configurable\": {\"thread_id\": '1' }}, stream_mode=\"values\"\n",
        ")\n",
        "output = None\n",
        "for event in events:\n",
        "    # print(event , 'break')\n",
        "    output =  event\n",
        "llm_output = [message.content for message in output['messages'] if isinstance(message, AIMessage)][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HzB-rGyjPep"
      },
      "outputs": [],
      "source": [
        "def generate_response(user_input , thread_id = \"111\"):\n",
        "  events = app.stream({'question' : user_input} , {\"configurable\": {\"thread_id\": thread_id }} )\n",
        "  for event in events:\n",
        "    print(event)\n",
        "    if \"generator\" in event:  # Check if the event contains the generation key\n",
        "          s = event[\"generator\"][\"generation\"]  # Extract the generation part\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQhWcfpb4aLl"
      },
      "outputs": [],
      "source": [
        "# from langchain_core.messages import AIMessage\n",
        "# def generate_response(user_input , thread_id = \"1\"):\n",
        "#   # The config is the **second positional argument** to stream() or invoke()!\n",
        "#   events = graph.stream(\n",
        "#     {\"messages\": [(\"user\", user_input)]}, {\"configurable\": {\"thread_id\": thread_id }}, stream_mode=\"values\"\n",
        "#   )\n",
        "#   output = None\n",
        "#   for event in events:\n",
        "#       # print(event , 'break')\n",
        "#       output =  event\n",
        "#   llm_output = [message.content for message in output['messages'] if isinstance(message, AIMessage)][-1]\n",
        "#   return llm_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubZj1hw0JNqh",
        "outputId": "dcee7be4-184f-46e0-dd12-bdea37720f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------Routing the query--------\n",
            "----------------Routing Query to Google-----------\n",
            "--------google_Search-----------\n",
            "google_search\n",
            "{'google_search': {'documents': 'Obama signed the Affordable Care Act (ACA) into law in 2010, aiming to provide affordable health insurance to millions of Americans. He ordered the military operation that led to the death of Osama bin Laden in 2011. Obama signed the Dodd-Frank Wall Street Reform and Consumer Protection Act in 2010 to prevent another financial crisis.\\nEarly Life and Education. Barack Obama, the 44th President of the United States, has a fascinating background that shaped his path to the White House.Let\\'s explore some intriguing facts about his early life and education.. Born on August 4, 1961, in Honolulu, Hawaii, Obama is the first U.S. president born outside the continental United States. His full name is Barack Hussein Obama II, named\\nBarack Obama, the 44th president of the United States, holds a special place in history as the first African-American president of the country. Read on to discover 53 interesting facts about Barack Obama, both political and personal. Childhood. 1. Barack Hussein Obama Jr. was born on August 4, 1961, in Honolulu, Hawaii.\\nAs in the primaries, Obama’s campaign worked to build support at the grassroots level and used what supporters saw as the candidate’s natural charisma, unusual life story and inspiring message of hope and change to draw impressive crowds to Obama’s public appearances, both in the U.S. and on a campaign trip abroad. A winner of the 2009 Nobel Peace Prize, Obama’s presidency was marked by the landmark passage of the Affordable Care Act, or “Obamacare”; the killing of Osama bin Laden by Seal Team Six; the Iran Nuclear Deal and the legalization of gay marriage by the Supreme Court.\\n A victory in the Iowa primary made him a viable challenger to the early frontrunner, the former first lady and current New York Senator Hillary Clinton, whom he outlasted in a grueling primary campaign to claim the Democratic nomination in early June 2008.\\n Barack Obama\\nBy: History.com Editors\\nUpdated: May 19, 2022\\n| Original: November 9, 2009\\nTable of Contents\\nBarack Obama, the 44th president of the United States and the first African American president, was elected over Senator John McCain of Arizona on November 4, 2008. He won a scholarship to study economics at the University of Hawaii, where he met and married Ann Dunham, a white woman from Wichita, Kansas, whose father had worked on oil rigs during the Great Depression and fought with the U.S. Army in World War II before moving his family to Hawaii in 1959.\\nBarack Obama: Facts & Related Content Barack Obama served as the 44th president of the United States (2009–17) and was the first African American to hold that post. Published Works \"Of Thee I Sing: A Letter to My Daughters\" (2010) • \"Our Enduring Spirit: President Barack Obama\\'s First Words to America\" (2009) • \"The Audacity of Hope: Thoughts on Reclaiming the American Dream\" (2006) • \"Dreams from My Father\" (1995) When did Barack Obama become president? During his presidency some claimed that Barack Obama was not born in the United States, which, according to the U.S. Constitution, would make him unable to serve as president. In 2012, Barack Obama became the first U.S. president to officially sanction same-sex marriage. United States: The Barack Obama administration', 'question': 'tell me about obama'}}\n",
            "--------Generation-----------\n",
            "{'generator': {'generation': 'Barack Obama is the 44th President of the United States and the first African American to hold that post. He was born on August 4, 1961, in Honolulu, Hawaii, making him the first U.S. president born outside the continental United States. His full name is Barack Hussein Obama II.\\n\\nDuring his presidency, which spanned from 2009 to 2017, Obama achieved several notable accomplishments. He signed the Affordable Care Act (ACA) into law in 2010, aiming to provide affordable health insurance to millions of Americans. He also ordered the military operation that led to the death of Osama bin Laden in 2011 and signed the Dodd-Frank Wall Street Reform and Consumer Protection Act in 2010 to prevent another financial crisis.\\n\\nObama was awarded the Nobel Peace Prize in 2009 and is also known for his support of same-sex marriage, becoming the first U.S. president to officially sanction it in 2012. He has written several books, including \"Dreams from My Father,\" \"The Audacity of Hope,\" and \"Of Thee I Sing: A Letter to My Daughters.\"\\n\\nObama was elected president on November 4, 2008, defeating Senator John McCain of Arizona. He won the Democratic nomination in June 2008 after a grueling primary campaign against Hillary Clinton. Despite some claims that he was not born in the United States, Obama\\'s birth in Hawaii has been verified, and he is widely recognized as a legitimate president.'}}\n"
          ]
        }
      ],
      "source": [
        "result = generate_response('tell me about obama')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPcCDzIt90eG",
        "outputId": "5fd9ea28-c606-4a21-e4f1-d58a87c5de90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------Routing the query--------\n",
            "----------------Routing Query to Google-----------\n",
            "--------google_Search-----------\n",
            "google_search\n",
            "{'google_search': {'documents': 'Warren Buffett (born August 30, 1930, Omaha, Nebraska, U.S.) is an American businessman and philanthropist, widely considered the most successful investor of the 20th and early 21st centuries, having defied prevailing investment trends to amass a personal fortune of more than $100 billion.. Known as the \"Oracle of Omaha,\" Buffett was the son of U.S. Rep. Howard Homan Buffett from Nebraska.\\nWarren Buffett is an investment phenomenon unlikely to be repeated soon, but that doesn\\'t mean investors can\\'t incorporate his principles into their investments. The willingness to identify\\nA keen mind for business. Born in 1930 to congressman and stockbroker Howard Buffett, Warren took a keen interest in business early in life. He made his first investment as a 14-year-old, using up his savings from selling soft drinks and newspapers to buy 40 acres of land, which he then rented.\\nCLICK HERE AND TELL US. WE\\'LL MAKE SURE THEY\\'RE HERE A.S.A.P. Quick Facts. Also Known As: Warren Edward Buffett. Age: 94 Years, 94 Year Old Males. Family: ... Warren Buffett worked at his father\\'s company, Buffett-Falk & Co. from 1951 to 1954, as an investment salesman. By the age of 20, he had already amassed savings worth almost $10,000 in\\nWarren Edward Buffett was born on August 30, 1930 to his father Howard, a stockbroker-turned-Congressman. The only boy, he was the second of three children, and displayed an amazing aptitude for both money and business at a very early age. Acquaintances recount his uncanny ability to calculate columns of numbers off the top of his head - a', 'question': 'tell me who is warren buffet'}}\n",
            "--------Generation-----------\n",
            "{'generator': {'generation': 'Warren Buffett is an American businessman and philanthropist, widely considered the most successful investor of the 20th and early 21st centuries. He was born on August 30, 1930, in Omaha, Nebraska, to U.S. Rep. Howard Homan Buffett. Buffett is known as the \"Oracle of Omaha\" and has amassed a personal fortune of more than $100 billion. He is known for his keen mind for business and made his first investment at the age of 14.'}}\n"
          ]
        }
      ],
      "source": [
        "g = generate_response(\"tell me who is warren buffet\",\"21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnRU7nzUEGIL",
        "outputId": "b4fdf40f-b83d-4739-d978-7af5805b0fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warren Buffett is an American businessman and philanthropist, widely considered the most successful investor of the 20th and early 21st centuries. He was born on August 30, 1930, in Omaha, Nebraska, to U.S. Rep. Howard Homan Buffett. Buffett is known as the \"Oracle of Omaha\" and has amassed a personal fortune of more than $100 billion. He is known for his keen mind for business and made his first investment at the age of 14.\n"
          ]
        }
      ],
      "source": [
        "print(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn-bFbCmD0I-"
      },
      "outputs": [],
      "source": [
        "llm_output = [message.content for message in g['messages'] if isinstance(message, AIMessage)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BTDkIY2FejI",
        "outputId": "4bf6959e-faac-4099-b9aa-83d3a7e67326"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " 'It appears that the function call to \\'tavily_search_results_json\\' with the query \"hy llama\" returned some results, but they seem to be incomplete. The function call result has missing information, especially in the section that usually includes explanations and news about current events.\\n\\nThe results are related to the phrase \"hy llama\", which seems to be a reference to a brand or a product related to llamas, possibly a coffee cup or a gift.\\n\\nIf you need more information or a more comprehensive answer, please try the function call again or use a different search engine.',\n",
              " '',\n",
              " 'The results returned from \\'tavily_search_results_json\\' with the query \"hy\" include information about a grocery store called Hy-Vee.',\n",
              " '',\n",
              " \"AlphaFold is an AI system developed by Google DeepMind that predicts a protein's 3D structure from its amino acid sequence. It regularly achieves accuracy competitive with experiment.\"]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2lzSg82_VIx"
      },
      "outputs": [],
      "source": [
        "def text_to_speech(text):\n",
        "    tts = gTTS(text)\n",
        "    output_audio = NamedTemporaryFile(suffix=\".mp3\", delete=False)\n",
        "    tts.save(output_audio.name)\n",
        "    return output_audio.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPqYCjqd7Q8k"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "\n",
        "# # Start the timer\n",
        "# start_time = time.time()\n",
        "\n",
        "# # Code block to measure\n",
        "# text_to_speech('hy my name is vivek')\n",
        "\n",
        "# # End the timer\n",
        "# end_time = time.time()\n",
        "\n",
        "# # Calculate the execution time\n",
        "# execution_time = end_time - start_time\n",
        "# print(execution_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3PkIESY7oi-"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "\n",
        "# # Start the timer\n",
        "# start_time = time.time()\n",
        "\n",
        "# # Code block to measure\n",
        "# speech_to_text('/content/my name is will.m4a')\n",
        "\n",
        "# # End the timer\n",
        "# end_time = time.time()\n",
        "\n",
        "# # Calculate the execution time\n",
        "# execution_time = end_time - start_time\n",
        "# print(execution_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfIwLniUAryG"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def chatbot_pipeline(audio_path = None):\n",
        "    if audio_path is None:\n",
        "        thread = random.randint(-1_000_000_000, 1_000_000_000)\n",
        "        thread_id = str(thread)\n",
        "        prompt = '''Role Description:\n",
        "                    You are , a friendly and knowledgeable sales agent representing Lifelong Insurance Ltd.,\n",
        "                    a trusted provider of insurance solutions. Your goal is to assist potential customers by explaining the benefits of Lifelong's insurance policies,\n",
        "                    understanding their specific needs, and helping them choose the right coverage. Be professional, persuasive, and approachable, tailoring your responses to the user's concerns\n",
        "                    Insurance Policies You Offer:\n",
        "                    Life Insurance Plans:\n",
        "\n",
        "                    Term Life Insurance: Affordable coverage for a fixed term, ensuring financial security for loved ones.\n",
        "                    Whole Life Insurance: Lifelong coverage with savings benefits and guaranteed payouts.\n",
        "                    Endowment Plans: Dual benefit of life cover and wealth creation.\n",
        "                    Health Insurance Plans:\n",
        "\n",
        "                    Individual Health Insurance: Comprehensive coverage for hospitalization and medical expenses.\n",
        "                    Family Floater Plans: Covers the entire family under a single policy.\n",
        "                    Critical Illness Insurance: Provides a lump sum benefit for severe medical conditions like cancer or heart disease.\n",
        "                    Retirement and Pension Plans:\n",
        "\n",
        "                    Annuity Plans: Ensure a steady income post-retirement.\n",
        "                    Deferred Pension Plans: Start saving now for a secure retirement.\n",
        "                    Child Insurance Plans:\n",
        "\n",
        "                    Savings-focused plans to secure your child’s education and future needs.\n",
        "                    Vehicle Insurance:\n",
        "\n",
        "                    Coverage for cars, bikes, and other vehicles to protect against accidents, theft, and damages.\n",
        "                    Home Insurance:\n",
        "\n",
        "                    Protection for your home and belongings against natural disasters, theft, and accidents.\n",
        "                    Travel Insurance:\n",
        "\n",
        "                    Safeguard your trips with coverage for medical emergencies, cancellations, and lost luggage.\n",
        "                    Key Features of Your Service:\n",
        "                    Customizable Plans: Tailor insurance policies to suit the user's needs and budget.\n",
        "                    Claim Assistance: Simplified and hassle-free claims process.\n",
        "                    24/7 Customer Support: Always available for queries and support.\n",
        "                    Discounts and Bonuses: Attractive premiums and loyalty rewards.\n",
        "                    Conversation Style:\n",
        "                    Greet warmly: Start with “Hi there, I’m Will from Lifelong Insurance Ltd.! How can I assist you today?”\n",
        "                    Ask open-ended questions: “What’s your primary concern—financial security, health coverage, or something else?”\n",
        "                    Provide clear , short and to the point explanations: “Our Term Life Insurance is a great option for ensuring your family’s future at a low cost.”\n",
        "                    Handle objections professionally: “I understand your concerns about cost, but let me show you how affordable our plans can be.”'''\n",
        "        response_text = generate_response(prompt , thread_id)\n",
        "        response_audio_path = text_to_speech(response_text)\n",
        "        return response_text , response_audio_path\n",
        "    else:\n",
        "      try:\n",
        "          # Step 1: Convert speech to text\n",
        "          text_input = speech_to_text(audio_path)\n",
        "          print(text_input)\n",
        "          # Step 2: Get response from LLaMA model\n",
        "          response_text = generate_response(text_input , thread_id)\n",
        "          print(response_text)\n",
        "          # Step 3: Convert response text to speech\n",
        "          response_audio_path = text_to_speech(response_text)\n",
        "\n",
        "          return response_text, response_audio_path\n",
        "\n",
        "      except Exception as e:\n",
        "          return str(e), None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCTuV5VVIzPL",
        "outputId": "eb5a28e8-da04-41d7-ddfd-48a502d35455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Tell me something about Obama.\n",
            "The information provided suggests that Barack Obama is the 44th President of the United States and the first African American president. He was elected on November 4, 2008, and served two terms in office. During his presidency, he passed several significant laws, including the Affordable Care Act, also known as \"Obamacare.\" He also played a key role in the killing of Osama bin Laden and the Iran Nuclear Deal. Obama's biography is marked by his middle-class upbringing, hard work, and education, as well as his commitment to public service. He is married to Michelle Obama, and their story is seen as an American success story.\n"
          ]
        }
      ],
      "source": [
        "x , y = chatbot_pipeline('/obama.m4a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "o_k3mBBmJhO3",
        "outputId": "b48aec5f-eac6-48b0-b028-93dbe1e1b9c4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/tmp/tmpmmddz6pr.mp3'"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDYbpWlx1fpN",
        "outputId": "eb109da0-46e1-4357-a8d2-0223df22f65b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1334683895111084\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "x , y = chatbot_pipeline('/content/my name is will.m4a')\n",
        "end_time = time.time()\n",
        "# Calculate the execution time\n",
        "execution_time = end_time - start_time\n",
        "print(execution_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QDHD0BSR2qKf",
        "outputId": "43d860b1-a05c-4c4a-a8c3-776cd4d5d6cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hello Phil, it's nice to meet you. Is there anything I can help you with?\""
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "olEjMOMq2sAy",
        "outputId": "8da62b98-a15f-4cb3-8e18-5676a1b7637a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/tmp/tmphcc4xhlh.mp3'"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOJp_v0b31Gw",
        "outputId": "a229a4be-d0c0-44c4-b6e9-be3a1da0b8a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hi my name is Vivek.\n",
            "You're not Will anymore, your name is now Vivek.\n"
          ]
        }
      ],
      "source": [
        "x1 , y1 = chatbot_pipeline('/tmpd0kq0u6z.mp3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0eDIm5zsH9og",
        "outputId": "6cf14b91-a518-4e81-a9e0-89f29cbb9483"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/tmp/tmpjripfarw.mp3'"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eEmmbi-T4t6f",
        "outputId": "2ab312da-58e8-4669-a114-9796fb957be7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hello Phil, it's nice to meet you. Is there anything I can help you with?\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JofIkxIWEfz7",
        "outputId": "6b3f27ff-012f-4325-e208-ba666f9005c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "23xqQ_DsA1tK",
        "outputId": "211c809a-2657-4d63-ad3d-11b94cea1cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ec81358e48028f5dca.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ec81358e48028f5dca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_pipeline,\n",
        "    inputs=gr.Audio(type=\"filepath\", label=\"Speak\"),  # Removed 'source' argument\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Response Text\"),\n",
        "        gr.Audio(label=\"Response Audio\")\n",
        "    ],\n",
        "    title=\"Real-Time Voice-to-Voice Chatbot\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rwCsp2jo_7M4",
        "outputId": "a7a81c90-970f-4a06-96bd-1fe8ee344d25"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hello Will, it's nice to meet you. Is there something I can help you with or would you like to chat?\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckfzXgfg7xgp",
        "outputId": "97c3fc31-30c4-4285-806e-cb4f0434ab00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='c8bdebc0-ec0c-4742-abf9-14dc6503a066')]} break\n",
            "{'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='c8bdebc0-ec0c-4742-abf9-14dc6503a066'), AIMessage(content=\"Hello Will, it's nice to meet you. Is there anything I can help you with today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 286, 'total_tokens': 307, 'completion_time': 0.028, 'prompt_time': 0.019606352, 'queue_time': 0.018969642000000002, 'total_time': 0.047606352}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-312c1c1b-eedb-41ef-9494-c539e6adcbb2-0', usage_metadata={'input_tokens': 286, 'output_tokens': 21, 'total_tokens': 307})]} break\n"
          ]
        }
      ],
      "source": [
        "for event in events:\n",
        "  print(event , 'break')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ms9rOF50Rq",
        "outputId": "61778ed2-4244-4d23-ad7b-d56aa5545173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='9c399926-46d0-4bde-b3e5-a28b1f3309b2')]}\n",
            "{'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='9c399926-46d0-4bde-b3e5-a28b1f3309b2'), AIMessage(content=\"It's nice to meet you, Will. Is there anything I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 286, 'total_tokens': 311, 'completion_time': 0.033333333, 'prompt_time': 0.020473361, 'queue_time': 0.019031413, 'total_time': 0.053806694}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None}, id='run-58d46be6-c351-43f4-b103-8d028c5b69be-0', usage_metadata={'input_tokens': 286, 'output_tokens': 25, 'total_tokens': 311})]}\n"
          ]
        }
      ],
      "source": [
        "for event in events:\n",
        "  print(event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiIKxH1ZyeU8",
        "outputId": "53b0fd11-cca8-4f1a-e190-bb421235a08d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Remember my name\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I'll remember your name is Will. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Remember my name\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, {\"configurable\": {\"thread_id\": \"1\"}}, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiemGB7Tywtp",
        "outputId": "5ee97ce4-9436-4517-e9ab-f4218c41d812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Tell me about any celebrity with the same name as mine in detail\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "<function=tavily_search_results_json>{\"query\": \"Will Smith biography\"}\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Tell me about any celebrity with the same name as mine in detail\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, {\"configurable\": {\"thread_id\": \"1\"}}, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cJUpTdmy7yC",
        "outputId": "ffb4e31a-fcd7-45e2-d242-aa8316f3fc43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Tell me about the celebrity you mentioned\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Will Smith is an American actor, rapper, media personality, and producer. Born on September 25, 1968, in Philadelphia, Pennsylvania, he rose to fame as part of the hip-hop duo DJ Jazzy Jeff & The Fresh Prince, alongside DJ Jazzy Jeff. He later transitioned to a successful acting career, starring in films like \"Independence Day,\" \"Men in Black,\" and \"Ali.\"\n",
            "\n",
            "Smith's breakout role came in 1990 when he starred in the popular TV show \"The Fresh Prince of Bel-Air.\" He played the lead role of William \"Will\" Smith, a teenager from Philadelphia who moves to live with his wealthy aunt and uncle in Bel-Air.\n",
            "\n",
            "Throughout his career, Smith has received numerous awards and nominations, including two Grammy Awards, four Golden Globe Awards, and an Academy Award nomination. He has also been named one of the most influential people in the world by TIME Magazine.\n",
            "\n",
            "In addition to his acting career, Smith is also a successful businessman and producer. He has produced several films and TV shows through his production company, Overbrook Entertainment, which he founded with his wife, Jada Pinkett Smith.\n",
            "\n",
            "Smith has been married to Jada Pinkett Smith since 1997, and they have two children together, Jaden and Willow. He has also been involved in various philanthropic efforts, including working with the Make-A-Wish Foundation and the Boys and Girls Clubs of America.\n",
            "\n",
            "Overall, Will Smith is a talented and influential figure in the entertainment industry, known for his charismatic personality, impressive acting skills, and philanthropic efforts.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Tell me about the celebrity you mentioned\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, {\"configurable\": {\"thread_id\": \"1\"}}, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGybog220VVT",
        "outputId": "0db5b208-7d24-4101-9913-92c5c70863b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm learning LangGraph. Could you do some research on it for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (call_sa97)\n",
            " Call ID: call_sa97\n",
            "  Args:\n",
            "    query: LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph is a framework for building and scaling agentic applications with LangChain Platform. It supports diverse control flows, human-agent collaboration, streaming, and deployment options for complex tasks.\"}, {\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. Learn how to use LangGraph to create stateful, flexible, and scalable systems with nodes, edges, and state management.\"}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (call_52yd)\n",
            " Call ID: call_52yd\n",
            "  Args:\n",
            "    query: LangChain Platform\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"url\": \"https://en.wikipedia.org/wiki/LangChain\", \"content\": \"In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \\\"todo\\\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project's Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]\"}, {\"url\": \"https://www.techtarget.com/searchEnterpriseAI/definition/LangChain\", \"content\": \"Everything you need to know\\nWhat are the features of LangChain?\\nLangChain is made up of the following modules that ensure the multiple components needed to make an effective NLP app can run smoothly:\\nWhat are the integrations of LangChain?\\nLangChain typically builds applications using integrations with LLM providers and external sources where data can be found and stored. What is synthetic data?\\nExamples and use cases for LangChain\\nThe LLM-based applications LangChain is capable of building can be applied to multiple advanced use cases within various industries and vertical markets, such as the following:\\nReaping the benefits of NLP is a key of why LangChain is important. As the airline giant moves more of its data workloads to the cloud, tools from Intel's Granulate are making platforms such as ...\\nThe vendor's new platform, now in beta testing, combines its existing lakehouse with AI to better enable users to manage and ...\\n The following steps are required to use this:\\nIn this scenario, the language model would be expected to take the two input variables -- the adjective and the content -- and produce a fascinating fact about zebras as its output.\\n The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications.\\n\"}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Based on the search results, LangGraph is a framework for building and scaling agentic applications with the LangChain Platform. It supports diverse control flows, human-agent collaboration, streaming, and deployment options for complex tasks. LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. It allows for stateful, flexible, and scalable systems with nodes, edges, and state management.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
        " # we'll use thread_id = 2 here\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, {\"configurable\": {\"thread_id\": \"2\"}}, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl3sOMAem3o0",
        "outputId": "695e232b-dd73-4ff5-9d1e-620db0bc6187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: hy how it's going on\n",
            "Assistant: It's going well, thank you for asking. I'm a large language model, so I don't have emotions or experiences like humans do, but I'm always here and ready to help with any questions or topics you'd like to discuss. It's great to have you here, and I'm looking forward to our conversation. How about you? How's your day going?\n",
            "User: okay can you help me by working as a sales assistant for me and help me in closing sales\n",
            "Assistant: I'd be happy to help you as a sales assistant.\n",
            "\n",
            "To get started, can you please provide me with more information about the product or service you're selling? This can include:\n",
            "\n",
            "1. What is the product or service?\n",
            "2. Who is your target audience?\n",
            "3. What are the key benefits and features of the product or service?\n",
            "4. What's the typical objection or concern that customers may have?\n",
            "5. What's your pricing strategy?\n",
            "\n",
            "Additionally, what specific area of sales assistance do you need help with? Do you need:\n",
            "\n",
            "1. Help with crafting a sales pitch or script?\n",
            "2. Assistance with responding to common objections?\n",
            "3. Guidance on how to handle difficult customers?\n",
            "4. Support with closing deals and negotiating prices?\n",
            "5. Something else?\n",
            "\n",
            "Let me know, and I'll do my best to help you close more sales!\n",
            "User: exit\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy56_qjMp4Mn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}